{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coursera face recognition.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM52Sk2BbyDR+NodFfejVWj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nisarg03/Tracing-people-with-Facial-Recognition-using-OCR/blob/main/Coursera_face_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mfxLnsNWZx3"
      },
      "source": [
        "#Required Libraries\n",
        "import zipfile\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "import pytesseract\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# loading the face detection classifier\n",
        "face_cascade = cv.CascadeClassifier('readonly/haarcascade_frontalface_default.xml')\n",
        "SCALE_FACTOR = 1.3\n",
        "NEIGHBOURS = 5\n",
        "\n",
        "display(face_cascade)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ayIpADRWhDS"
      },
      "source": [
        "def img_to_text(orignalimage):\n",
        "    # Convert to gray scale\n",
        "    img = orignalimage.convert('L')\n",
        "    \n",
        "    #extract the text\n",
        "    text = pytesseract.image_to_string(img)\n",
        "    \n",
        "    \n",
        "    # Filter Punctuations\n",
        "    words = text.replace('-\\n','').replace('\\n',' ').replace('.','').replace(',','')\n",
        "    \n",
        "    # List in lowercase and remove blanks\n",
        "    words = words.lower().split(' ')\n",
        "    if len(words) > 0:\n",
        "        if ('' in words):\n",
        "            words.remove('')\n",
        "    \n",
        "    # only keep unique values\n",
        "    words = list(dict.fromkeys(words))\n",
        "    return(words)\n",
        "\n",
        "def img_to_faces (pil_img):\n",
        "    face_images=[]\n",
        "    # Convert to OpenCV format\n",
        "    open_cv_image = np.array(pil_img) \n",
        "    open_cv_image = open_cv_image[:, :, ::-1].copy() \n",
        "    \n",
        "    # loading the face detection classifier\n",
        "    faces = face_cascade.detectMultiScale(open_cv_image,SCALE_FACTOR,NEIGHBOURS)\n",
        "    # Crop image to only the faces\n",
        "    for x,y,w,h in faces:\n",
        "        im = pil_img.crop((x,y,x+w,y+h))\n",
        "        face_images.append(im)\n",
        "    return (face_images)\n",
        "def Search(word):\n",
        "    \n",
        "    faces_found = SearchNewsPaperData(word,newspaper)\n",
        "    display(\"Searching for \"+word)\n",
        "    for item in faces_found:\n",
        "        display(\"Results found in file {}\".format(item))\n",
        "        if len(faces_found[item]['faces']) > 0:\n",
        "            display(MakeSingleImage(faces_found[item]['faces'],120))\n",
        "        else:\n",
        "            display(\"No faces found.\")    \n",
        "    return()\n",
        "\n",
        "def SearchNewsPaperData(wordToFind,data):\n",
        "    newspapers={}\n",
        "    for item in data:\n",
        "        # Get the words from the newspaper\n",
        "        words = data[item]['words']\n",
        "        # Get the faces.\n",
        "        faces = data[item]['faces']\n",
        "        f = find_Words(wordToFind,words)\n",
        "        if f > 0:\n",
        "            # Found a match, store in a dictionary.\n",
        "            newspapers.update({item:{'faces':faces}})\n",
        "    return (newspapers)\n",
        "\n",
        "def MakeSingleImage(images,picture_size):\n",
        "    # Determining the size of the image\n",
        "    img_per_row = min(5,len(images)) #To have not more than 5 images per row\n",
        "    total_width = picture_size * 5\n",
        "    max_height = int(picture_size * np.ceil(len(images)/5))\n",
        "    new_im = Image.new('RGB', (total_width, max_height))\n",
        "    x_offset = 0\n",
        "    y_offset = 0\n",
        "    count = 0\n",
        "    for im in images:\n",
        "        # Resize the image as a square to the desired size.\n",
        "        im_sized = resize(im,picture_size)\n",
        "        # paste into the master image.\n",
        "        new_im.paste(im_sized, (x_offset,y_offset))\n",
        "        x_offset += picture_size\n",
        "        count += 1\n",
        "        if (count % 5) == 0: #To change line after 5th image\n",
        "            y_offset += picture_size\n",
        "            x_offset = 0\n",
        "    return(new_im)\n",
        "\n",
        "def find_Words(wordToSearch,words):\n",
        "    # Exact match(Lion = Lion) or Partial Match(Lion subset of Lions).\n",
        "    if (wordToSearch in words) or (wordToSearch in s for s in words):\n",
        "        return (1)\n",
        "    else:\n",
        "        # No match.\n",
        "        return(0)\n",
        "\n",
        "def resize(pil_img,basewidth):\n",
        "    wpercent = (basewidth / float(pil_img.size[0]))\n",
        "    hsize = int((float(pil_img.size[1]) * float(wpercent)))\n",
        "    return(pil_img.resize((basewidth, hsize), Image.ANTIALIAS))\n",
        "#Zip File Initiation\n",
        "zip_name = os.getcwd() + \"/readonly/small_img.zip\"\n",
        "zip_file_var = zipfile.ZipFile(zip_name,mode = 'r')\n",
        "\n",
        "#Initialize the Newspaper Dictionary\n",
        "newspaper = {}\n",
        "files = zip_file_var.namelist()\n",
        "\n",
        "#Iterate through all of the files\n",
        "for file in files:\n",
        "    print(file)\n",
        "    newspaper_img = Image.open(io.BytesIO(zip_file_var.read(file)))\n",
        "    \n",
        "    #Get Text from Image\n",
        "    words = img_to_text(newspaper_img)\n",
        "    \n",
        "    #Get Faces from Image\n",
        "    faces = img_to_faces(newspaper_img)\n",
        "    \n",
        "    newspaper.update({file:{'words':words,'faces':faces}})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JyPNB47WyYm"
      },
      "source": [
        "Search(\"christopher\")\n",
        "\n",
        "Search(\"mark\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}